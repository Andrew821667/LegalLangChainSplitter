
# üß™ –¢–ï–°–¢ –ò–°–ü–†–ê–í–õ–ï–ù–ù–û–ô –í–ï–†–°–ò–ò

import sys
sys.path.append('.')

from legal_langchain_splitter_token_fixed import LegalLangChainSplitter

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –≤ –¢–û–ö–ï–ù–ê–•
config = {
    "min_chunk_size": 500,    # –¢–û–ö–ï–ù–´
    "max_chunk_size": 1200,   # –¢–û–ö–ï–ù–´
    "chunk_overlap": 100,     # –¢–û–ö–ï–ù–´
    "encoding_name": "cl100k_base"
}

print("üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–æ–π –≤–µ—Ä—Å–∏–∏...")

splitter = LegalLangChainSplitter(config)

# –¢–µ—Å—Ç–æ–≤—ã–π –ø—Ä–∞–≤–æ–≤–æ–π —Ç–µ–∫—Å—Ç
test_text = """
–°—Ç–∞—Ç—å—è 1. –û—Å–Ω–æ–≤–Ω—ã–µ –ø–æ–Ω—è—Ç–∏—è

–í –Ω–∞—Å—Ç–æ—è—â–µ–º –§–µ–¥–µ—Ä–∞–ª—å–Ω–æ–º –∑–∞–∫–æ–Ω–µ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è —Å–ª–µ–¥—É—é—â–∏–µ –æ—Å–Ω–æ–≤–Ω—ã–µ –ø–æ–Ω—è—Ç–∏—è:

–ü—É–Ω–∫—Ç 1. –ü–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ - –ª—é–±–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è, –æ—Ç–Ω–æ—Å—è—â–∞—è—Å—è –∫ –ø—Ä—è–º–æ –∏–ª–∏ –∫–æ—Å–≤–µ–Ω–Ω–æ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–º—É –∏–ª–∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ–º–æ–º—É —Ñ–∏–∑–∏—á–µ—Å–∫–æ–º—É –ª–∏—Ü—É (—Å—É–±—ä–µ–∫—Ç—É –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö).

–ü—É–Ω–∫—Ç 2. –û–ø–µ—Ä–∞—Ç–æ—Ä - –≥–æ—Å—É–¥–∞—Ä—Å—Ç–≤–µ–Ω–Ω—ã–π –æ—Ä–≥–∞–Ω, –º—É–Ω–∏—Ü–∏–ø–∞–ª—å–Ω—ã–π –æ—Ä–≥–∞–Ω, —é—Ä–∏–¥–∏—á–µ—Å–∫–æ–µ –∏–ª–∏ —Ñ–∏–∑–∏—á–µ—Å–∫–æ–µ –ª–∏—Ü–æ, —Å–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å–Ω–æ –∏–ª–∏ —Å–æ–≤–º–µ—Å—Ç–Ω–æ —Å –¥—Ä—É–≥–∏–º–∏ –ª–∏—Ü–∞–º–∏ –æ—Ä–≥–∞–Ω–∏–∑—É—é—â–∏–µ –∏ (–∏–ª–∏) –æ—Å—É—â–µ—Å—Ç–≤–ª—è—é—â–∏–µ –æ–±—Ä–∞–±–æ—Ç–∫—É –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö.

–°—Ç–∞—Ç—å—è 2. –ü—Ä–∞–≤–æ–≤–æ–µ —Ä–µ–≥—É–ª–∏—Ä–æ–≤–∞–Ω–∏–µ

–û—Ç–Ω–æ—à–µ–Ω–∏—è, —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö, –æ—Å—É—â–µ—Å—Ç–≤–ª—è–µ–º–æ–π —Ñ–µ–¥–µ—Ä–∞–ª—å–Ω—ã–º–∏ –æ—Ä–≥–∞–Ω–∞–º–∏ –≥–æ—Å—É–¥–∞—Ä—Å—Ç–≤–µ–Ω–Ω–æ–π –≤–ª–∞—Å—Ç–∏, –æ—Ä–≥–∞–Ω–∞–º–∏ –≥–æ—Å—É–¥–∞—Ä—Å—Ç–≤–µ–Ω–Ω–æ–π –≤–ª–∞—Å—Ç–∏ —Å—É–±—ä–µ–∫—Ç–æ–≤ –†–æ—Å—Å–∏–π—Å–∫–æ–π –§–µ–¥–µ—Ä–∞—Ü–∏–∏ –∏ –æ—Ä–≥–∞–Ω–∞–º–∏ –º–µ—Å—Ç–Ω–æ–≥–æ —Å–∞–º–æ—É–ø—Ä–∞–≤–ª–µ–Ω–∏—è, —Ä–µ–≥—É–ª–∏—Ä—É—é—Ç—Å—è —Ñ–µ–¥–µ—Ä–∞–ª—å–Ω—ã–º –∑–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å—Å—Ç–≤–æ–º.
""" * 4  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —á–∞–Ω–∫–æ–≤

test_metadata = {
    "title": "–§–ó –û –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö",
    "legal_document": True
}

print(f"üìä –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç: {splitter._count_tokens(test_text)} —Ç–æ–∫–µ–Ω–æ–≤")

# –†–∞–∑–±–∏–≤–∞–µ–º
chunks = splitter.split(test_metadata, test_text)

print(f"üì¶ –ü–æ–ª—É—á–µ–Ω–æ —á–∞–Ω–∫–æ–≤: {len(chunks)}")

for i, chunk in enumerate(chunks):
    metadata = chunk.metadata
    content = chunk.page_content
    
    print(f"\nüìÑ –ß–∞–Ω–∫ {i+1}:")
    print(f"   üî¢ –¢–æ–∫–µ–Ω–æ–≤: {metadata['token_count']}")
    print(f"   üìè –°–∏–º–≤–æ–ª–æ–≤: {metadata['char_count']}")
    print(f"   ‚úÖ –í –¥–∏–∞–ø–∞–∑–æ–Ω–µ: {metadata['in_target_range']}")
    print(f"   üìù –ù–∞—á–∞–ª–æ: {content[:80]}...")

print("\nüéØ –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∏–∞–ø–∞–∑–æ–Ω–æ–≤:")
for i, chunk in enumerate(chunks):
    tokens = chunk.metadata['token_count']
    in_range = 500 <= tokens <= 1200
    status = "‚úÖ" if in_range else "‚ö†Ô∏è"
    print(f"{status} –ß–∞–Ω–∫ {i+1}: {tokens} —Ç–æ–∫–µ–Ω–æ–≤")
